{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/Testrepo/mlruns/2', creation_time=1723539801480, experiment_id='2', last_update_time=1723539801480, lifecycle_stage='active', name='random-forest-hyperopt', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(data_path: str, num_trials: int):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param(\"max_depth\", params[\"max_depth\"])\n",
    "            mlflow.log_param(\"min_samples_leaf\", params[\"min_samples_leaf\"])\n",
    "            mlflow.log_param(\"min_samples_split\", params[\"min_samples_split\"])\n",
    "            mlflow.log_param(\"n_estimators\", params[\"n_estimators\"])\n",
    "            mlflow.log_param(\"random_state\", params[\"random_state\"])\n",
    "            \n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_val)\n",
    "            result = (y_pred==y_val)\n",
    "            error = 1-sum(result)/len(result)\n",
    "            print(error)\n",
    "            \n",
    "            mlflow.log_metric(\"error\", error)\n",
    "            mlflow.sklearn.log_model(RandomForestRegressor, artifact_path=\"artifact\")\n",
    "            mlflow.set_tag(\"model\", rf)\n",
    "            mlflow.end_run()\n",
    "        return {'loss': error, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "\n",
    "X_train, y_train = load_pickle(os.path.join(\"./output\", \"train.pkl\"))\n",
    "X_val, y_val = load_pickle(os.path.join(\"./output\", \"val.pkl\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "result = (y_pred==y_val)\n",
    "accuracy = sum(result)/len(result)\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099173553719008                                    \n",
      "  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0                                                                             \n",
      "  7%|▋         | 1/15 [00:02<00:28,  2.01s/trial, best loss: 0.8099173553719008]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429752066115702                                                              \n",
      " 13%|█▎        | 2/15 [00:04<00:25,  1.93s/trial, best loss: 0.8099173553719008]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768595041322314                                                               \n",
      " 20%|██        | 3/15 [00:05<00:23,  1.92s/trial, best loss: 0.8099173553719008]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7851239669421488                                                              \n",
      " 27%|██▋       | 4/15 [00:07<00:20,  1.90s/trial, best loss: 0.768595041322314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520661157024793                                                             \n",
      " 33%|███▎      | 5/15 [00:09<00:18,  1.89s/trial, best loss: 0.768595041322314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933884297520661                                                              \n",
      " 40%|████      | 6/15 [00:11<00:16,  1.87s/trial, best loss: 0.7520661157024793]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7851239669421488                                                              \n",
      " 47%|████▋     | 7/15 [00:13<00:15,  1.88s/trial, best loss: 0.7520661157024793]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768595041322314                                                               \n",
      " 53%|█████▎    | 8/15 [00:15<00:13,  1.87s/trial, best loss: 0.7520661157024793]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7603305785123967                                                              \n",
      " 60%|██████    | 9/15 [00:17<00:11,  1.91s/trial, best loss: 0.7520661157024793]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6528925619834711                                                               \n",
      " 67%|██████▋   | 10/15 [00:19<00:09,  1.87s/trial, best loss: 0.7520661157024793]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:37:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099173553719008                                                               \n",
      " 73%|███████▎  | 11/15 [00:20<00:07,  1.85s/trial, best loss: 0.6528925619834711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:38:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933884297520661                                                               \n",
      " 80%|████████  | 12/15 [00:22<00:05,  1.90s/trial, best loss: 0.6528925619834711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:38:03 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859504132231404                                                               \n",
      " 87%|████████▋ | 13/15 [00:24<00:03,  1.89s/trial, best loss: 0.6528925619834711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:38:05 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768595041322314                                                                \n",
      " 93%|█████████▎| 14/15 [00:26<00:01,  1.89s/trial, best loss: 0.6528925619834711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 10:38:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:28<00:00,  1.90s/trial, best loss: 0.6528925619834711]\n"
     ]
    }
   ],
   "source": [
    "run_optimization(data_path=\"./output\", num_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
